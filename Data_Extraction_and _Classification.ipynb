{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d41852ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\saitu\\anaconda3\\lib\\site-packages (4.9.0)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from selenium) (0.10.2)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from selenium) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from selenium) (2022.9.14)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: idna in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: outcome in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e06890b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver_manager in c:\\users\\saitu\\anaconda3\\lib\\site-packages (3.8.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from webdriver_manager) (4.64.1)\n",
      "Requirement already satisfied: requests in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from webdriver_manager) (2.28.1)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from webdriver_manager) (1.0.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from webdriver_manager) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from packaging->webdriver_manager) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (1.26.11)\n",
      "Requirement already satisfied: colorama in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from tqdm->webdriver_manager) (0.4.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4d798a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyvirtualdisplay in c:\\users\\saitu\\anaconda3\\lib\\site-packages (3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyvirtualdisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0c89898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import time\n",
    "from selenium import webdriver\n",
    "import random\n",
    "from csv import writer\n",
    "import pandas as pd\n",
    "from pyvirtualdisplay import Display\n",
    "import pickle\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1a95a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraction of youtube urls and video ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3f52b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "Entered same height condition at i =  37\n",
      "Increased sleep time to  2\n",
      "38\n",
      "Entered same height condition at i =  38\n",
      "Increased sleep time to  2\n",
      "39\n",
      "Entered same height condition at i =  39\n",
      "Increased sleep time to  2\n",
      "40\n",
      "Entered same height condition at i =  40\n",
      "Increased sleep time to  2\n",
      "41\n",
      "Entered same height condition at i =  41\n",
      "Increased sleep time to  2\n",
      "42\n",
      "Entered same height condition at i =  42\n",
      "Increased sleep time to  2\n",
      "43\n",
      "Entered same height condition at i =  43\n",
      "Increased sleep time to  2\n",
      "44\n",
      "Entered same height condition at i =  44\n",
      "Increased sleep time to  2\n",
      "45\n",
      "Entered same height condition at i =  45\n",
      "Increased sleep time to  2\n",
      "46\n",
      "Entered same height condition at i =  46\n",
      "Increased sleep time to  2\n",
      "47\n",
      "Entered same height condition at i =  47\n",
      "Increased sleep time to  2\n",
      "48\n",
      "Entered same height condition at i =  48\n",
      "Increased sleep time to  2\n",
      "49\n",
      "Entered same height condition at i =  49\n",
      "Increased sleep time to  2\n",
      "50\n",
      "written in  0.000973816712697347\n"
     ]
    }
   ],
   "source": [
    "#This code contains two functions, scroll_to_end and write_to_csv_and_txt.\n",
    "\n",
    "#The scroll_to_end function takes a webdriver object as an argument, and scrolls down the webpage until the bottom is reached. \n",
    "#It achieves this by executing JavaScript code that scrolls the webpage to the bottom of the page. \n",
    "#It then sleeps for a random amount of time between 2 and 3 seconds, and repeats the process until the height of the page no longer changes. \n",
    "#If the function executes 50 scrolls or more than 5.5 hours elapse, the function stops scrolling and returns the webdriver object. \n",
    "\n",
    "\n",
    "def scroll_to_end(driver):\n",
    "    start_time = time.time()\n",
    "    prev_ht=driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "    i = 0\n",
    "    sleep_time = 2\n",
    "    while True:\n",
    "        i+=1\n",
    "        print(i)\n",
    "        if i == 50:\n",
    "            return driver\n",
    "        if i % 100 == 0:\n",
    "            print(i, \"scrolls executed\")\n",
    "            current_time = time.time()\n",
    "            if current_time - start_time > (3600 * 5.5):\n",
    "                print(\"5 hours elapsed; breaking at i = \", i)\n",
    "                break\n",
    "        driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "        time.sleep(sleep_time + random.uniform(0, 1))\n",
    "        ht=driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "        if prev_ht == ht:\n",
    "            time.sleep(2)\n",
    "            print(\"Entered same height condition at i = \", i)\n",
    "            sleep_time += 0\n",
    "            print(\"Increased sleep time to \", sleep_time)\n",
    "            \n",
    "            if sleep_time >= 20:\n",
    "                print(\"Sleep time hit 20s; breaking\")\n",
    "                break\n",
    "            \n",
    "        prev_ht = ht\n",
    "    return driver\n",
    "#The write_to_csv_and_txt function takes the same webdriver object as an argument and extracts the titles and URLs of all the hyperlinks that have an \"id\" attribute equal to \"video-title\". \n",
    "#It then returns the extracted information as a list of lists containing the title and URL of each hyperlink.\n",
    "#Note that the write_to_csv_and_txt function does not actually write anything to a CSV or text file, despite its name. It simply extracts the data and returns it in the form of a list of lists containing the title and URL of each hyperlink. \n",
    "#If you want to write this data to a file, you will need to modify the function to do so.\n",
    "def write_to_csv_and_txt(driver):    \n",
    "    time_start = time.time()\n",
    "    out_dict = driver.execute_script(\"var result = []; \" +\n",
    "    \"var all = document.getElementsByTagName('a'); \" +\n",
    "    \"for (var i=0, max=all.length; i < max; i++) { \" +\n",
    "    \"    if(all[i].getAttribute('id') ==  'video-title')\" +                    \n",
    "    \"        result.push([all[i].getAttribute('title'), all[i].getAttribute('href')]); \" +\n",
    "    \"} \" +\n",
    "    \" return result; \")\n",
    "    \n",
    "    # Write the video URLs to the CSV file\n",
    "    with open('Djokovic.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        csv_writer = writer(csvfile)\n",
    "        csv_writer.writerows(out_dict)\n",
    "    \n",
    "    # Extract the video IDs and write them to the text file\n",
    "    with open('video_ids.txt', 'w') as outfile:\n",
    "        for row in out_dict:\n",
    "            youtube_url = row[1]\n",
    "            video_id_match = re.search(r'(?<=v=)[^&#]+', youtube_url)\n",
    "            video_id_match = video_id_match or re.search(r'(?<=be/)[^&#]+', youtube_url)\n",
    "            video_id = video_id_match.group(0) if video_id_match else None\n",
    "            if video_id:\n",
    "                outfile.write(video_id + '\\n')\n",
    "    \n",
    "    time_end = time.time()\n",
    "    \n",
    "    print(\"written in \", (time_end - time_start) / 60)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(\"https://www.youtube.com/results?search_query=novak+djokovic+deportation\")\n",
    "    driver = scroll_to_end(driver)\n",
    "    write_to_csv_and_txt(driver)\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6e4fa99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-api-python-client in c:\\users\\saitu\\anaconda3\\lib\\site-packages (2.86.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from google-api-python-client) (2.17.3)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from google-api-python-client) (0.1.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from google-api-python-client) (2.11.0)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.59.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2.28.1)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (4.22.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\saitu\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2022.9.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d240d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import googleapiclient.discovery\n",
    "from googleapiclient.discovery import build\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a58f900",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraction of the Video Metadata and comments data using the video IDs text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d95b523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b28d4a6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "HttpError",
     "evalue": "<HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId=fu_i4cyowWY&textFormat=plainText&key=AIzaSyC9qCYZGzOp2zjgfR5BUUFlEv9VSxnRgGQ&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.\". Details: \"[{'message': 'The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.', 'domain': 'youtube.commentThread', 'reason': 'commentsDisabled', 'location': 'videoId', 'locationType': 'parameter'}]\">",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22148\\1882357856.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;31m# Call the YouTube API to retrieve the comments for the video\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             comments_response = youtube.commentThreads().list(\n\u001b[0m\u001b[0;32m     26\u001b[0m                 \u001b[0mpart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'snippet'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[0mvideoId\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\googleapiclient\\_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mpositional_parameters_enforcement\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mPOSITIONAL_WARNING\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpositional_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\googleapiclient\\http.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, http, num_retries)\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 938\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    939\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpostproc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHttpError\u001b[0m: <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId=fu_i4cyowWY&textFormat=plainText&key=AIzaSyC9qCYZGzOp2zjgfR5BUUFlEv9VSxnRgGQ&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.\". Details: \"[{'message': 'The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.', 'domain': 'youtube.commentThread', 'reason': 'commentsDisabled', 'location': 'videoId', 'locationType': 'parameter'}]\">"
     ]
    }
   ],
   "source": [
    "api_key = 'AIzaSyC9qCYZGzOp2zjgfR5BUUFlEv9VSxnRgGQ'\n",
    "youtube = googleapiclient.discovery.build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "# Open the text file containing the video ids\n",
    "with open('video_ids.txt', 'r') as id_file:\n",
    "\n",
    "    # Open the CSV file and write headings\n",
    "    with open('video_metadata.csv', 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow(['Video ID', 'Title', 'Description', 'Published At', 'Channel ID', 'Channel Title', 'Category ID', 'View Count', 'Like Count', 'Dislike Count', 'Comment ID', 'Comment', 'Comment Timestamp', 'Duration'])\n",
    "\n",
    "        # Loop through each video id in the file\n",
    "        for video_id in id_file:\n",
    "\n",
    "            # Strip any whitespace or newline characters from the video id\n",
    "            video_id = video_id.strip()\n",
    "\n",
    "            # Call the YouTube API to retrieve the video metadata\n",
    "            video_response = youtube.videos().list(\n",
    "                part='snippet,statistics,contentDetails',\n",
    "                id=video_id\n",
    "            ).execute()\n",
    "\n",
    "            # Call the YouTube API to retrieve the comments for the video\n",
    "            comments_response = youtube.commentThreads().list(\n",
    "                part='snippet',\n",
    "                videoId=video_id,\n",
    "                textFormat='plainText'\n",
    "            ).execute()\n",
    "\n",
    "            # Extract the metadata for the video\n",
    "            video_data = video_response['items'][0]['snippet']\n",
    "            video_title = video_data['title']\n",
    "            video_description = video_data['description']\n",
    "            video_published_at = video_data['publishedAt']\n",
    "            video_channel_id = video_data['channelId']\n",
    "            video_channel_title = video_data['channelTitle']\n",
    "            video_category_id = video_data['categoryId']\n",
    "            video_view_count = video_response['items'][0]['statistics'].get('viewCount', 0)\n",
    "            video_like_count = video_response['items'][0]['statistics'].get('likeCount', 0)\n",
    "            video_dislike_count = video_response['items'][0]['statistics'].get('dislikeCount', 0)\n",
    "            video_comment_count = video_response['items'][0]['statistics'].get('commentCount', 0)\n",
    "            video_duration = video_response['items'][0]['contentDetails'].get('duration', '')\n",
    "\n",
    "            # Extract the comments for the video\n",
    "            comments_data = comments_response['items']\n",
    "            for comment in comments_data:\n",
    "                comment_data = comment['snippet']['topLevelComment']['snippet']\n",
    "                comment_id = comment['snippet']['topLevelComment']['id']\n",
    "                comment_text = comment_data['textDisplay']\n",
    "                comment_timestamp = comment_data['publishedAt']\n",
    "\n",
    "                # Write the video metadata and comment data to the CSV file\n",
    "                writer.writerow([video_id, video_title, video_description, video_published_at, video_channel_id, video_channel_title, video_category_id, video_view_count, video_like_count, video_dislike_count, comment_id, comment_text, comment_timestamp, video_duration])\n",
    "\n",
    "#The below error occurs due to comments being disabled for a certain video.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8b7e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversion of video duration to seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "279ec945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1695adca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv file into a pandas dataframe\n",
    "df = pd.read_csv('video_metadata_updated.csv')\n",
    "\n",
    "# define a function to convert the duration from ISO 8601 format to seconds\n",
    "def duration_to_seconds(Video_Duration):\n",
    "    # extract the minutes and seconds using regex\n",
    "    minutes_match = re.findall(r'PT(\\d+)M', Video_Duration)\n",
    "    seconds_match = re.findall(r'(\\d+)S', Video_Duration)\n",
    "    if len(minutes_match) == 0 or len(seconds_match) == 0:\n",
    "        # invalid duration format\n",
    "        return 0\n",
    "    minutes = int(minutes_match[0])\n",
    "    seconds = int(seconds_match[0])\n",
    "    # calculate the total duration in seconds\n",
    "    total_seconds = minutes * 60 + seconds\n",
    "    return total_seconds\n",
    "\n",
    "# apply the function to the 'Duration' column and create a new 'duration_seconds' column\n",
    "df['Video_duration_seconds'] = df['Video_Duration'].apply(duration_to_seconds)\n",
    "\n",
    "# save the updated dataframe to a new csv file\n",
    "df.to_csv('video_metadata_updated__.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb762b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing the Comment and video timestamps difference and checking for the core condition of classifying the comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3407b089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5566ccf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a pandas dataframe\n",
    "df = pd.read_csv('video_metadata_updated.csv')\n",
    "\n",
    "# Convert the Comment_Timestamp and Video_Timestamp columns to datetime format\n",
    "df['Comment_Timestamp'] = pd.to_datetime(df['Comment_Timestamp'])\n",
    "df['Video_Timestamp'] = pd.to_datetime(df['Video_Timestamp'])\n",
    "\n",
    "# Calculate the duration of the video in seconds and add to a new column\n",
    "df['Duration_Seconds'] = pd.to_timedelta(df['Video_Duration']).dt.total_seconds()\n",
    "\n",
    "# Calculate the timestamp difference between comment and video in seconds and add to a new column\n",
    "df['Timestamp_Difference_Seconds'] = (df['Comment_Timestamp'] - df['Video_Timestamp']).dt.total_seconds()\n",
    "\n",
    "# Calculate the video duration/2 in seconds and add to a new column\n",
    "df['Half_Duration_Seconds'] = df['Duration_Seconds']/2\n",
    "\n",
    "# Add a new column for response type\n",
    "df['Response_Type'] = ''\n",
    "\n",
    "# Iterate through each row in the dataframe\n",
    "for index, row in df.iterrows():\n",
    "    # Check if the timestamp difference is greater than half the video duration\n",
    "    if row['Timestamp_Difference_Seconds'] < row['Half_Duration_Seconds']:\n",
    "        # If true, mark the response type as steady state\n",
    "        df.at[index, 'Response_Type'] = 'Early response'\n",
    "    else:\n",
    "        # If false, mark the response type as early response\n",
    "        df.at[index, 'Response_Type'] = 'Steady State response'\n",
    "\n",
    "# Write the updated dataframe to the same input CSV file\n",
    "df.to_csv('video_metadata_updated_____.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
